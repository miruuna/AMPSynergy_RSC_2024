{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import MDAnalysis as mda\n",
    "from MDAnalysis.analysis.align import rotation_matrix\n",
    "from MDAnalysis.analysis.rms import rmsd\n",
    "from MDAnalysis.analysis.rms import rmsd as rmsd_mdanalysis\n",
    "import MDAnalysis.transformations as trans\n",
    "from MDAnalysis.analysis.dihedrals import Ramachandran\n",
    "\n",
    "import umap\n",
    "import hdbscan\n",
    "\n",
    "\n",
    "from Bio.PDB.DSSP import DSSP\n",
    "from Bio.PDB import PDBParser\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_dir = os.getenv('DATA_FOLDER')\n",
    "b_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peptides and simulation details\n",
    "combined = True\n",
    "title=\"WF1a_WF2\"\n",
    "peptide = \"WF1a\"\n",
    "ref_pep = 1 # reference peptide\n",
    "save_files = True\n",
    "\n",
    "\n",
    "#Set start/end time and chop the peptide\n",
    "start_sim = None \n",
    "stop_sim = None \n",
    "   \n",
    "# To use C_alpha atoms only\n",
    "c_alpha = True\n",
    "step_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_name = \"last500ns\"\n",
    "base_folder = f\"{b_dir}/umap_hdbscan/{folder_name}\"\n",
    "Path(base_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "save_files = True\n",
    "\n",
    "if save_files:\n",
    "    if combined:\n",
    "        working_output_dir =f\"{base_folder}/{peptide}\"\n",
    "        Path(working_output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        working_output_dir =f\"{base_folder}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(v1, v2):\n",
    "    \"\"\"\n",
    "    Calculates the distances between two arrays\n",
    "    \"\"\"\n",
    "    x1, y1, z1 = v1[0], v1[1], v1[2]\n",
    "    x2, y2, z2 = v2[0], v2[1], v2[2]\n",
    "    distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2 + (z2 - z1)**2)\n",
    "    return distance\n",
    "\n",
    "def unpack_lists(x):\n",
    "    return_list = []\n",
    "    for i in x:\n",
    "        for e in i:\n",
    "            return_list.append(e)\n",
    "    return return_list\n",
    "\n",
    "def get_distances_each_carbon_per_pep(u, frames, n_frames, amino_acid_count, \n",
    "                                      start_res, end_res, c_alpha_only=True):    \n",
    "\n",
    "    if c_alpha_only:\n",
    "        backbone = u.select_atoms(f\"name CA and resid {start_res}:{end_res}\")\n",
    "    else:\n",
    "        backbone = u.select_atoms(f\"backbone and resid {start_res}:{end_res}\")\n",
    "        \n",
    "    residues_range = amino_acid_count\n",
    "\n",
    "    all_distances = np.full(\n",
    "        (n_frames, int(len([(i, j) for i in range(residues_range) \n",
    "                            for j in range(residues_range) if i!=j])/2)\n",
    "        ), fill_value=np.NaN\n",
    "        )\n",
    "\n",
    "    all_pos = np.full((n_frames, backbone.n_atoms * 3), fill_value=np.NaN)  \n",
    "\n",
    "    # align to references structure (mean atom positions)\n",
    "\n",
    "    for frame_index, ts in tqdm(enumerate(u.trajectory[frames]), total=n_frames):\n",
    "        all_pos[frame_index] = backbone.positions.ravel()\n",
    "        results = []\n",
    "        i_already = []\n",
    "        for i in range(backbone.n_atoms):\n",
    "            i_already.append(i)\n",
    "            for j in range(backbone.n_atoms):\n",
    "                if i!=j and j not in i_already:\n",
    "                    result = calculate_distance(\n",
    "                        backbone.positions[i].ravel(), \n",
    "                        backbone.positions[j].ravel())\n",
    "                    results.append(result)\n",
    "        all_distances[frame_index] = results     \n",
    "\n",
    "    return all_pos, all_distances\n",
    "\n",
    "def get_dihedrals_individual_prot(u, start_id, end_id):\n",
    "\n",
    "    u.trajectory[0]\n",
    "    r = u.select_atoms(f\"resid {start_id}-{end_id}\")\n",
    "    print(f\"starting with residues {start_id} - {end_id}\")\n",
    "    R = Ramachandran(r).run(step=step_size)\n",
    "    angles = R.results.angles\n",
    "    phi = angles[:, :, 0]\n",
    "    psi = angles[:, :, 1]\n",
    "    combined_angles = np.dstack((phi, psi)).flatten()\n",
    "    combined_angles = np.reshape(combined_angles, (phi.shape[0], phi.shape[1]*2))\n",
    "\n",
    "    return combined_angles, phi, psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_pep ={1:4, 2:3, 3:2, 4:1}\n",
    "\n",
    "class Peptide:\n",
    "    \n",
    "    def __init__(self, xtc_file_path, tpr_file_path, peptide_number, \n",
    "                 peptide_order, amino_acid_count):\n",
    "        self.xtc_file_path = xtc_file_path\n",
    "        self.tpr_file_path = tpr_file_path\n",
    "        self.peptide_number = peptide_number\n",
    "        self.peptide_order = peptide_order\n",
    "        self.amino_acid_count = amino_acid_count\n",
    "        self.u = mda.Universe(tpr_file_path, xtc_file_path)\n",
    "        self.u.trajectory.add_transformations(trans.unwrap(self.u.select_atoms(f\"backbone\")))\n",
    "        if peptide_order == 1:\n",
    "            self.pep_dict = {\n",
    "                k: ((k-1)*amino_acid_count+1, k*amino_acid_count) for k in range(1, peptide_number+1)\n",
    "            }\n",
    "        else:\n",
    "            self.pep_dict = {\n",
    "                k: (len(self.u.select_atoms(\"protein\").residues.resids)-match_pep[k]*amino_acid_count + 1, \n",
    "                    len(self.u.select_atoms(\"protein\").residues.resids)-(match_pep[k]-1)*amino_acid_count) \n",
    "                    for k in range(1, peptide_number+1)\n",
    "            }\n",
    "\n",
    "        self.start_id = self.pep_dict[1][0]\n",
    "        self.end_id = self.pep_dict[1][1]\n",
    "\n",
    "    def get_pep_dict(self):\n",
    "        return self.pep_dict\n",
    "    \n",
    "    def load_traj(self):\n",
    "       \n",
    "        start_sim, stop_sim, step = self.u.trajectory.check_slice_indices(None, None, None)\n",
    "\n",
    "        frames = np.arange(start_sim, stop_sim, step_size)\n",
    "        n_frames = frames.size\n",
    "\n",
    "        frames_pd = pd.DataFrame(frames)\n",
    "        frames_pd.to_csv(f\"{working_output_dir}/frames.csv\")\n",
    "\n",
    "        return frames, n_frames\n",
    "    \n",
    "\n",
    "    def get_ref_pos(self, c_alpha_only=False):\n",
    "        \"\"\"\n",
    "        Rotates the reference peptide according to the first position and then returns\n",
    "        the mean structure positions\n",
    "        \"\"\"\n",
    "        print(f\"Starting analysis for peptide: {peptide}\")\n",
    "        print(f\"Using reference pep: {ref_pep}, with start id: {self.start_id} and end_id: {self.end_id}\")\n",
    "\n",
    "        \n",
    "        if c_alpha_only == True:\n",
    "            backbone_ref = self.u.select_atoms(f\"name CA and resid {self.start_id}:{self.end_id}\")\n",
    "        else:\n",
    "            backbone_ref = self.u.select_atoms(f\"resid {self.start_id}:{self.end_id}\")\n",
    "        self.u.trajectory[0]\n",
    "        \n",
    "        frames, n_frames = self.load_traj()\n",
    "        first_pos_ref = backbone_ref.unwrap()\n",
    "\n",
    "        all_pos1 = np.full((n_frames, backbone_ref.n_atoms, 3), fill_value=np.NaN)\n",
    "\n",
    "        for frame_index, _ in tqdm(enumerate(self.u.trajectory[frames]), total=n_frames):\n",
    "            backbone_ref.unwrap(inplace=True)\n",
    "            backbone_ref.translate(-backbone_ref.center_of_geometry())\n",
    "            R, rmsd = rotation_matrix(backbone_ref.positions, first_pos_ref)\n",
    "            backbone_ref.rotate(R)\n",
    "            all_pos1[frame_index] = backbone_ref.positions\n",
    "\n",
    "        ref_pos = np.mean(all_pos1, axis=0)\n",
    "\n",
    "        return ref_pos\n",
    "    \n",
    "    def get_distances(self):\n",
    "        \"\"\"\n",
    "        Return the n-n distances between all the Calpha atoms in the WF1a peptides\n",
    "        \"\"\"\n",
    "\n",
    "        frames, n_frames = self.load_traj()\n",
    "\n",
    "        return [\n",
    "            get_distances_each_carbon_per_pep(self.u, frames, n_frames, self.amino_acid_count, \n",
    "                                              resids[0], resids[1], c_alpha_only=True)[1]\n",
    "            for k, resids in self.pep_dict.items()                                 \n",
    "        ]\n",
    "    \n",
    "    def get_dihedrals(self):\n",
    "        \n",
    "        return [\n",
    "            get_dihedrals_individual_prot(self.u,resids[0], resids[1], c_alpha_only=True)[1]\n",
    "            for k, resids in self.pep_dict.items()                                 \n",
    "        ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_1 = Peptide(\n",
    "    f\"/Volumes/miru_backup/jade_2synergy/popg/8_pg/WF1a_pg/md_0_1_combined.xtc\",\n",
    "    f\"/Volumes/miru_backup/jade_2synergy/popg/8_pg/WF1a_pg/md_0_1.tpr\",\n",
    "    8, 1, 20 \n",
    ")\n",
    "pep_2 = Peptide(\n",
    "    f\"/Volumes/miru_backup/jade_2synergy/popg/8_pg/WF1a_pg_2/md_0_1_combined.xtc\",\n",
    "    f\"/Volumes/miru_backup/jade_2synergy/popg/8_pg/WF1a_pg_2/md_0_1.tpr\",\n",
    "    8, 1, 20\n",
    ")\n",
    "\n",
    "WF1a_WF2_1 = Peptide(\n",
    "    f\"/Volumes/miru_backup/jade_2synergy/popg/WF1a_WF2_pg/md_0_1_combined.xtc\",\n",
    "    f\"/Volumes/miru_backup/jade_2synergy/popg/WF1a_WF2_pg/md_0_1.tpr\",\n",
    "    4, 1, 20 \n",
    ")\n",
    "\n",
    "WF1a_WF2_2 = Peptide(\n",
    "    f\"/Volumes/miru_backup/jade_2synergy/popg_replicas/WF1a_WF2_pg_2/md_0_1_combined.xtc\",\n",
    "    f\"/Volumes/miru_backup/jade_2synergy/popg_replicas/WF1a_WF2_pg_2/md_0_1.tpr\",\n",
    "    4, 1, 20 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set simulation directories\n",
    "\n",
    "\n",
    "pep_1 = Peptide(\n",
    "    f\"../WF1a_pg/md_0_1_combined.xtc\",\n",
    "    f\"..//WF1a_pg/md_0_1.tpr\",\n",
    "    8, 1, 20 \n",
    ")\n",
    "pep_2 = Peptide(\n",
    "    f\"../WF1a_pg_2/md_0_1_combined.xtc\",\n",
    "    f\"../WF1a_pg_2/md_0_1.tpr\",\n",
    "    8, 1, 20\n",
    ")\n",
    "\n",
    "WF1a_WF2_1 = Peptide(\n",
    "    f\"../WF1a_WF2_pg/md_0_1_combined.xtc\",\n",
    "    f\"../WF1a_WF2_pg/md_0_1.tpr\",\n",
    "    4, 1, 20 \n",
    ")\n",
    "\n",
    "WF1a_WF2_2 = Peptide(\n",
    "    f\"..//WF1a_WF2_pg_2/md_0_1_combined.xtc\",\n",
    "    f\"../WF1a_WF2_pg_2/md_0_1.tpr\",\n",
    "    4, 1, 20 \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate distances\n",
    "\n",
    "distances_WF1a_WF2_1 = WF1a_WF2_1.get_distances()\n",
    "distances_WF1a_WF2_2 = WF1a_WF2_2.get_distances()\n",
    "distances_pep_1 = pep_1.get_distances()\n",
    "distances_pep_2 = pep_2.get_distances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all data\n",
    "\n",
    "all_distances_sim1 = np.vstack(\n",
    "    [\n",
    "         *distances_WF1a_WF2_1, *distances_WF1a_WF2_2,\n",
    "        *distances_pep_1, *distances_pep_2\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def get_normalized_data(data):\n",
    "\n",
    "    max_values = np.amax(data, axis=0)\n",
    "    normalized_data = data / max_values\n",
    "    normalized_data = np.nan_to_num(normalized_data, nan=0)\n",
    "    \n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove low variance columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distances = pd.DataFrame(all_distances_sim1, columns=range(all_distances_sim1.shape[1]))\n",
    "\n",
    "column_variance = df_distances.var()\n",
    "\n",
    "plt.hist(column_variance.tolist())\n",
    "plt.xlabel(\"Variance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Carbon alpha distances variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [i for i, c in enumerate(df_distances.var().tolist()) if c<10]\n",
    "new_df = df_distances.drop(to_drop,axis=1)\n",
    "new_df.to_csv(f\"{working_output_dir}/distances_sim.csv\")\n",
    "\n",
    "hv_distances_sim1_2 = new_df.to_numpy()\n",
    "normalized_hv_distances1_2 = get_normalized_data(hv_distances_sim1_2)\n",
    "normalized_hv_distances1_2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f'{working_output_dir}/normalised_distances_{peptide}.npy', 'wb') as f:\n",
    "    np.save(f, normalized_hv_distances1_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{working_output_dir}/normalised_distances_{peptide}.npy', 'rb') as f:\n",
    "    normalized_hv_dih_distances1_2 = np.load(f, allow_pickle=True)\n",
    "\n",
    "normalized_hv_distances1_2 =normalized_hv_dih_distances1_2[:, :102]\n",
    "normalized_hv_distances1_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "save_files = True\n",
    "combined = True\n",
    "\n",
    "params_dict = {\"min_cluster_size\": 70, \"cluster_selection_epsilon\": 1, \"n_neighbours\": 65, \"random_state\": 50,\n",
    " \"start_chop\": 0, \"end_chop\": 0}\n",
    "\n",
    "with open(f'{working_output_dir}/hyper_params.json', 'w') as f:\n",
    "    json.dump(params_dict, f)\n",
    "\n",
    "X_embedded = umap.UMAP(\n",
    "    n_neighbors=params_dict[\"n_neighbours\"],  # larger numbers forcus more on global properties (and increase computational effort required)\n",
    "    n_components=2,  # set the number of dimensions to reduce to\n",
    "    min_dist=0.0,    # must be 0.0 if points are to be clustered later with HDBSCAN\n",
    "    verbose=True,\n",
    "    n_jobs=1,        # use all available cores\n",
    "    random_state=params_dict[\"random_state\"]\n",
    ").fit_transform(normalized_hv_distances1_2)\n",
    "\n",
    "hdb = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=params_dict[\"min_cluster_size\"],              # minimum number of points for a group to be considered a cluster\n",
    "    cluster_selection_epsilon=params_dict[\"cluster_selection_epsilon\"],      # clusters closer than this distance apart will be merged\n",
    "    cluster_selection_method=\"leaf\"   # changes the way clusters are initialised. \"eom\" tends to lead to fewer clusters than \"leaf\"\n",
    ")\n",
    "\n",
    "hdb.fit(X_embedded)\n",
    "\n",
    "y_pred = hdb.fit_predict(X_embedded)\n",
    "y_pred = y_pred +1 \n",
    "\n",
    "\n",
    "colors = [\n",
    "    \"#4f8c9d\", \"#72e5ef\", \"#bbc3fe\", \"#800f76\",\n",
    "    \"#724363\", \"#1932bf\", \"#DC9D00\", \"#1f84ec\", \n",
    "    \"#8e3703\", \"#fbcab9\", \"#c00018\", \"#104b6d\", \"#fd7450\", \"#b38677\",\n",
    "    \"#4f8c9d\", \"#72e5ef\", \"#104b6d\", \"#bbc3fe\", \"#800f76\", \"#ed8bc7\",\n",
    "    \"#724363\", \"#ed2bb1\", \"#1932bf\", \"#8b6fed\", \"#1f84ec\", \n",
    "    \"#8e3703\", \"#fbcab9\", \"#c00018\", \"#fd7450\", \"#b38677\"\n",
    "    ]\n",
    "\n",
    "\n",
    "c=[colors[i] for i in y_pred]\n",
    "\n",
    "print(f\"Not in a cluster: {sum(y_pred==-1)} ({100 * sum(y_pred==-1) / y_pred.size:.2f}%)\")\n",
    "outliers = X_embedded[y_pred==-1]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1], cmap='Paired', s=30, c=c)\n",
    "plt.scatter(outliers[:,0], outliers[:,1], cmap='Paired', s=30,c='black')\n",
    "\n",
    "total_calc = 0\n",
    "for cluster in range(-1, max(y_pred)+1):    \n",
    "    mean = np.mean(X_embedded[y_pred==cluster], axis=0)\n",
    "    total_calc += X_embedded[y_pred==cluster].shape[0]\n",
    "    plt.text(\n",
    "        mean[0]+0.85, mean[1],\n",
    "        cluster,\n",
    "        fontsize=15\n",
    "    )\n",
    "\n",
    "\n",
    "first_line_title =f\" {peptide} peptides\" if combined else peptide\n",
    "plt.title(first_line_title,size=15,fontname=\"Times New Roman\", fontweight=\"bold\" )\n",
    "plt.title(f\"Outliers: {100 * sum(y_pred==0) / y_pred.size:.2f}%\", size=12,fontname=\"Times New Roman\", loc=\"right\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.savefig(f\"{working_output_dir}/{peptide}_clusters.png\", dpi=400, bbox_inches=\"tight\")\n",
    "cluster_labels = y_pred\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Clusters and Analyse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.DataFrame(cluster_labels)\n",
    "df_labels[\"System\"] = [\n",
    "    *[\"WF1a + WF2 I\" for i in cluster_labels[:251*4]],\n",
    "    *[\"WF1a + WF2 II\" for i in cluster_labels[251*4:251*8]],\n",
    "    *[\"WF1a Pure I\" for i in cluster_labels[251*8:251*16]],\n",
    "    *[\"WF1a Pure II\" for i in cluster_labels[251*16:251*24]]\n",
    "    ]\n",
    "df_labels[\"Time (ns)\"] = [\n",
    "    i%251 for i in range(len(cluster_labels))\n",
    "]\n",
    "df_labels[\"Peptide\"] =  [\n",
    "    *unpack_lists([[str(i) for x in range(251)] for i in range(1, 5)]),\n",
    "    *unpack_lists([[str(i) for x in range(251)] for i in range(1, 5)]),\n",
    "    *unpack_lists([[str(i) for x in range(251)] for i in range(1, 9)]),\n",
    "    *unpack_lists([[str(i) for x in range(251)] for i in range(1, 9)]),\n",
    "]\n",
    "df_labels = df_labels.rename(columns={0: \"Cluster\"})\n",
    "df_labels = df_labels[df_labels[\"Cluster\"]!=0]\n",
    "\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 2), sharex=True)\n",
    "\n",
    "g = sns.stripplot(data=df_labels, y=\"System\",\n",
    "                x=\"Cluster\",dodge=False, legend=True, size=15, jitter=True,c=\"#104b6d\",\n",
    "                 marker=\"o\",linewidth=1, alpha=.2, ax=ax).set_title(\"WF1a (t>500ns)\")\n",
    "ax.set_xticks(range(1, len(np.unique(cluster_labels))+1))\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f\"{working_output_dir}/all_clusters_per_system_{peptide}.png\", dpi=400, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_list_configs = {\n",
    "    \"WF1a\": [\n",
    "        \"pep1\", \"pep2\", \"pep3\", \"pep4\", \"pep1_2\", \"pep2_2\", \"pep3_2\", \"pep4_2\",\n",
    "        \"pep1_indiv\", \"pep2_indiv\", \"pep3_indiv\", \"pep4_indiv\", \n",
    "        \"pep5_indiv\", \"pep6_indiv\", \"pep7_indiv\", \"pep8_indiv\", \n",
    "        \"pep1_2_indiv\", \"pep2_2_indiv\", \"pep3_2_indiv\", \"pep4_2_indiv\",\n",
    "        \"pep5_2_indiv\", \"pep6_2_indiv\", \"pep7_2_indiv\", \"pep8_2_indiv\"\n",
    "    ],\n",
    "    \"WF2\": [\n",
    "        \"pep5\", \"pep6\", \"pep7\", \"pep8\", \"pep5_2\", \"pep6_2\", \"pep7_2\", \"pep8_2\",\n",
    "        \"pep1_indiv\", \"pep2_indiv\", \"pep3_indiv\", \"pep4_indiv\", \n",
    "        \"pep5_indiv\", \"pep6_indiv\", \"pep7_indiv\", \"pep8_indiv\", \n",
    "        \"pep1_2_indiv\", \"pep2_2_indiv\", \"pep3_2_indiv\", \"pep4_2_indiv\",\n",
    "        \"pep5_2_indiv\", \"pep6_2_indiv\", \"pep7_2_indiv\", \"pep8_2_indiv\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "pep_list_names = pep_list_configs.get(peptide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split by peptide\n",
    "n_frames = 251\n",
    "cluster_labels_pep1 = cluster_labels[:n_frames]\n",
    "cluster_labels_pep2 = cluster_labels[n_frames:2*n_frames]\n",
    "cluster_labels_pep3 = cluster_labels[2*n_frames:3*n_frames]\n",
    "cluster_labels_pep4 = cluster_labels[3*n_frames:4*n_frames]\n",
    "\n",
    "\n",
    "#Combine the peptide dataframes\n",
    "cluster_labels_time = pd.DataFrame([cluster_labels_pep1 , cluster_labels_pep2, cluster_labels_pep3, cluster_labels_pep4])\n",
    "cluster_labels_time = cluster_labels_time.T\n",
    "cluster_labels_time.columns = [\"pep1\", \"pep2\", \"pep3\", \"pep4\"] if peptide == \"WF1a\" \\\n",
    "      else [\"pep5\", \"pep6\", \"pep7\", \"pep8\"]\n",
    "\n",
    "cluster_labels_reshaped = cluster_labels.reshape(n_frames,24)\n",
    "\n",
    "cluster_labels_time = pd.DataFrame(cluster_labels_reshaped)\n",
    "\n",
    "cluster_labels_time.columns = pep_list_names\n",
    "\n",
    "#Save to file\n",
    "cluster_labels_time.to_csv(f\"{working_output_dir}/cluster_labels_{peptide}.csv\")\n",
    "\n",
    "frames_from_csv = pd.read_csv(f\"{working_output_dir}/frames.csv\")\n",
    "frames_from_csv = frames_from_csv.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "cluster_frames_saved = frames_from_csv.join(cluster_labels_time)\n",
    "cluster_frames_saved = cluster_frames_saved.rename(columns={\"0\":\"Timeframe\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster distribution per system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "\n",
    "color_map = {\n",
    "    i: colors[i] for i in range(-1, max(y_pred)+1)\n",
    "}\n",
    "\n",
    "def get_piechart(pep_list_names, subtitle):\n",
    "\n",
    "    counter_dict = {x:0 for x in np.unique(cluster_labels)}\n",
    "    total = 0\n",
    "    for k, v in counter_dict.items():\n",
    "        for pep in pep_list_names:\n",
    "            val = cluster_labels_time[[pep]].value_counts().get(k)\n",
    "            if val:\n",
    "                counter_dict[k]+= val\n",
    "                total += val\n",
    "    counter_dict = {k:v for k, v in counter_dict.items() if k!=0}\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pie([v for k, v in counter_dict.items()], labels=counter_dict.keys(), colors=color_map,\n",
    "            shadow=False, startangle=90, )\n",
    "    centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "    fig.gca().add_artist(centre_circle)\n",
    "\n",
    "    # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "    ax.axis('equal')  \n",
    "    plt.legend(labels=[f'{list(counter_dict.keys())[i]} {round(list(counter_dict.values())[i]/total*100)}%' \n",
    "    for i in range(len(counter_dict.keys()))], \n",
    "        bbox_to_anchor=(1,1))\n",
    "    plt.title(f\"{peptide} peptides - Cluster distribution \\n {subtitle}\",size=15,fontname=\"Times New Roman\", fontweight=\"bold\" )\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"{working_output_dir}/cluster_percentage_{subtitle}_{peptide}.png\", dpi=400, bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_piechart_with_arms(pep_list_names, subtitle):\n",
    "    counter_dict = {x:0 for x in np.unique(cluster_labels)}\n",
    "    total = 0\n",
    "    for k, v in counter_dict.items():\n",
    "        for pep in pep_list_names:\n",
    "            val = cluster_labels_time[[pep]].value_counts().get(k)\n",
    "            if val:\n",
    "                counter_dict[k]+= val\n",
    "                total += val\n",
    "    counter_dict = {k:v for k, v in counter_dict.items() if k!=0}\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "    wedges, texts = ax.pie([v for k, v in counter_dict.items()], \n",
    "    labels=counter_dict.keys(), colors=[color_map[i] for i in list(counter_dict.keys())] ,\n",
    "     wedgeprops=dict(width=0.5), startangle=-40, labeldistance=.58, textprops={'fontsize': 14})\n",
    "    centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "    fig.gca().add_artist(centre_circle)\n",
    "    # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "    ax.axis('equal')  \n",
    "\n",
    "\n",
    "    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.5)\n",
    "    kw = dict(arrowprops=dict(arrowstyle=\"-\"),\n",
    "            bbox=bbox_props, zorder=0, va=\"center\")\n",
    "    \n",
    "    total = sum([int(i) for i in counter_dict.values()])\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"{working_output_dir}/cluster_percentage_{subtitle}_{peptide}.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_piechart_with_arms([p for p in pep_list_names if \"indiv\" not in p], \"Combination Systems\")               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_piechart_with_arms([p for p in pep_list_names if \"indiv\" in p], \"Pure Systems\")               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dssp_to_struct(dssp_entry):\n",
    "        \"\"\"\n",
    "        Return the DSSP list associated with a dssp entry\n",
    "        \"\"\"\n",
    "        sequence = ''\n",
    "        sec_structure = ''\n",
    "        for z in range(len(dssp_entry)):\n",
    "                a_key = list(dssp_entry.keys())[z]\n",
    "                sequence += dssp_entry[a_key][1]\n",
    "                sec_structure += f\"{dssp_entry[a_key][2]}\"\n",
    "        sec_structure.replace(' ', \"C\")\n",
    "        \n",
    "        return sec_structure    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_pdb =f\"{working_output_dir}/pdbs_{peptide}_per_pep\"\n",
    "Path(output_dir_pdb).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def write_pdb_per_pep(pep, pep_dict, u, frames, n_frames, ref_pos, ref_struct=\"min_rmsd\"):\n",
    "    \"\"\"\n",
    "    Find the representative structure for each cluster and save to .pdb file\n",
    "    \"\"\"\n",
    "    start_id, end_id = pep_dict[pep]\n",
    "\n",
    "    backbone = u.select_atoms(f\"resid {start_id}:{end_id}\")\n",
    "\n",
    "    cluster_labels_pep = cluster_labels[(pep-1)*n_frames:pep*n_frames]\n",
    "\n",
    "\n",
    "    list_peptide, list_cluster, list_first_frame, list_cluster_frames,\\\n",
    "          list_the_frame, cluster_indexes, list_dssp, all_frames_coordinates = \\\n",
    "            [], [], [], [], [], [], [], []\n",
    "    \n",
    "\n",
    "    for cluster in np.unique(cluster_labels_pep):\n",
    "        \n",
    "        # ref structures will be first structure in a cluster \n",
    "        first_frame_index = np.where(cluster_labels_pep==cluster)[0][0]\n",
    "        first_frame = frames[first_frame_index]\n",
    "\n",
    "        frames, n_frames =  pep_1.load_traj()\n",
    "\n",
    "        # frames at which cluster is found\n",
    "        frames_indexes = np.where(cluster_labels_pep==cluster)[0]\n",
    "        frames_cluster = frames[frames_indexes]\n",
    "\n",
    "        list_cluster_frames.append(frames_cluster)\n",
    "        list_cluster.append(cluster)\n",
    "        cluster_indexes.append(frames_indexes)\n",
    "        list_peptide.append(pep)\n",
    "        list_first_frame.append(first_frame)\n",
    "\n",
    "        cluster_pos = np.full((len(frames_cluster), backbone.n_atoms, 3), fill_value=np.NaN)\n",
    "        cluster_rmsd = np.full((len(frames_cluster), 1), fill_value=np.NaN)\n",
    "\n",
    "        # align all and get positions\n",
    "        frames_coordinates = []\n",
    "        for frame_index, ts in enumerate(u.trajectory[frames_cluster]):\n",
    "            backbone.translate(-backbone.center_of_geometry())\n",
    "            R, rmsd_frame = rotation_matrix(backbone.positions, ref_pos)\n",
    "            backbone.rotate(R)\n",
    "            cluster_pos[frame_index] = backbone.positions\n",
    "            cluster_rmsd[frame_index] = rmsd_frame\n",
    "            frames_coordinates.append(u.trajectory.time)\n",
    "\n",
    "        all_frames_coordinates.append(frames_coordinates)\n",
    "\n",
    "        mean_rmsd = np.mean(cluster_rmsd)\n",
    "        difference_array = np.absolute(cluster_rmsd - mean_rmsd)\n",
    "\n",
    "        # find frame at which rmsd to mean position is smallest\n",
    "        rep_frame_index = difference_array.argmin()\n",
    "\n",
    "        rep_frame = frames_cluster[rep_frame_index]\n",
    "    \n",
    "        list_the_frame.append(rep_frame)\n",
    "\n",
    "        # load coordinates from representative frame\n",
    "        for frame_index, ts in enumerate(u.trajectory[[rep_frame]]):\n",
    "            # translate and rotate aroms\n",
    "            atoms = backbone\n",
    "            atoms.unwrap(inplace=True)\n",
    "            atoms.translate(-backbone.center_of_mass())\n",
    "\n",
    "            R, rmsd = rotation_matrix(backbone.positions, ref_pos)\n",
    "            atoms.rotate(R)\n",
    "\n",
    "            # write pdb\n",
    "            \n",
    "            atoms.write(f\"{output_dir_pdb}/{ref_struct}_cluster_{cluster}_pep{pep}.pdb\")\n",
    "\n",
    "            p = PDBParser()\n",
    "            structure = p.get_structure(f\"{cluster}_{pep}\", f\"{output_dir_pdb}/{ref_struct}_cluster_{cluster}_pep{pep}.pdb\")\n",
    "            model = structure[0]\n",
    "            dssp = DSSP(model, f\"{output_dir_pdb}/{ref_struct}_cluster_{cluster}_pep{pep}.pdb\", dssp='mkdssp')\n",
    "            list_dssp.append(dssp)\n",
    "\n",
    "    return (list_peptide, list_cluster, list_first_frame, list_cluster_frames, list_the_frame, cluster_indexes, list_dssp, all_frames_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# pepdict_combined refers to the actual simulation datat\n",
    "peptide_configs = {\n",
    "    \"WF1a\": {\n",
    "        1: (1, 20), 2: (21, 40), 3: (41, 60), 4: (61, 80), 5: (1, 20), 6: (21, 40),\n",
    "        7: (41, 60), 8: (61, 80), 9: (1, 20), 10: (21, 40), 11: (41, 60), 12: (61, 80),\n",
    "        13: (81, 100), 14: (101, 120), 15: (121, 140), 16: (141, 160), 17: (1, 20),\n",
    "        18: (21, 40), 19: (41, 60), 20: (61, 80), 21: (81, 100), 22: (101, 120),\n",
    "        23: (121, 140), 24: (141, 160)\n",
    "    },\n",
    "    \"WF2\": {\n",
    "        1: (81, 105), 2: (106, 130), 3: (131, 155), 4: (156, 180), 5: (81, 105),\n",
    "        6: (106, 130), 7: (131, 155), 8: (156, 180), 9: (1, 25), 10: (26, 50),\n",
    "        11: (51, 75), 12: (76, 100), 13: (1, 25), 14: (26, 50), 15: (51, 75),\n",
    "        16: (76, 100)\n",
    "    }\n",
    "}\n",
    "\n",
    "pep_dict_combined = peptide_configs.get(peptide)\n",
    "\n",
    "ref_pos = pep_1.get_ref_pos()\n",
    "\n",
    "list_peptide, list_cluster, list_first_frame, list_cluster_frames, \\\n",
    "    list_the_frame, list_the_indexes, list_the_dssp, list_all_frames_coordinates = \\\n",
    "           [], [], [], [], [], [], [], []\n",
    "\n",
    "\n",
    "for pep in tqdm(pep_dict_combined.keys()):\n",
    "    if pep in range(1, 5):\n",
    "        u = WF1a_WF2_1.u\n",
    "    elif pep in range(4,9):\n",
    "        u = WF1a_WF2_2.u\n",
    "    elif pep in range(8, 17):\n",
    "        u = pep_1.u\n",
    "    elif pep in range(16, 25):\n",
    "        u = pep_2.u\n",
    "    else:\n",
    "        u = None\n",
    "    frames, n_frames =  pep_1.load_traj()\n",
    "\n",
    "    list_peptide1, list_cluster1, list_first_frame1, list_cluster_frames1,\\\n",
    "         list_the_frame1, list_the_indexes1, list_the_dssp1, all_frames_coordinates1 = \\\n",
    "        write_pdb_per_pep(pep, pep_dict_combined, u, frames, n_frames, ref_pos=ref_pos)\n",
    "        \n",
    "    list_peptide.append(list_peptide1)\n",
    "    list_cluster.append(list_cluster1)\n",
    "    list_first_frame.append(list_first_frame1)\n",
    "    list_cluster_frames.append(list_cluster_frames1)\n",
    "    list_the_frame.append(list_the_frame1)\n",
    "    list_the_indexes.append(list_the_indexes1)\n",
    "    list_the_dssp.append(list_the_dssp1)\n",
    "    list_all_frames_coordinates.append(all_frames_coordinates1)\n",
    "\n",
    "structure_dataframe = pd.DataFrame([[unpack_lists(list_peptide)[k], unpack_lists(list_cluster)[k], \n",
    "                                unpack_lists(list_first_frame)[k], unpack_lists(list_cluster_frames)[k], \n",
    "                                unpack_lists(list_the_frame)[k], unpack_lists(list_the_indexes)[k], \n",
    "                                unpack_lists(list_the_dssp)[k], unpack_lists(list_all_frames_coordinates)[k]]\n",
    "                                for k in range(len(unpack_lists(list_cluster)))],\n",
    "                                columns=[\"peptide\", \"cluster\", \"first_frame\", \"cluster_frames\", \"the_frame\", \"indexes\", \"DSSP\", \"frames_cluster_coordinates\"])\n",
    "structure_dataframe[\"total_frames\"] = structure_dataframe.apply(lambda x: len(x[\"cluster_frames\"]), axis=1)\n",
    "structure_dataframe[\"total_indexes\"] = structure_dataframe.apply(lambda x: len(x[\"indexes\"]), axis=1)\n",
    "structure_dataframe[\"indexes\"] = structure_dataframe[\"indexes\"]+n_frames*(structure_dataframe[\"peptide\"]-1)\n",
    "structure_dataframe[\"DSSP\"] = structure_dataframe.apply(lambda x: dssp_to_struct(x[\"DSSP\"]), axis=1)\n",
    "structure_dataframe_to_save = structure_dataframe\n",
    "structure_dataframe_to_save[\"frames_cluster_coordinates\"] = structure_dataframe_to_save.apply(lambda x: \"_\".join([str(x) for x in x[\"frames_cluster_coordinates\"]]), axis=1)\n",
    "structure_dataframe_to_save[\"cluster_frames\"] = structure_dataframe_to_save.apply(lambda x: \"_\".join([str(x) for x in x[\"cluster_frames\"].tolist()]), axis=1)\n",
    "structure_dataframe_to_save.to_csv(f\"{working_output_dir}/structure_dssp_frames_different_ref.csv\")    \n",
    "structure_dataframe[\"cluster_frames\"] = structure_dataframe.apply(lambda x: [float(x) for x in x[\"cluster_frames\"].split(\"_\")], axis=1)\n",
    "structure_dataframe[\"frames_cluster_coordinates\"] = structure_dataframe.apply(lambda x: [float(x) for x in x[\"frames_cluster_coordinates\"].split(\"_\")], axis=1) \n",
    "\n",
    "# Convert the frames\n",
    "all_frames = list(set(unpack_lists(structure_dataframe[\"cluster_frames\"].tolist())))\n",
    "all_frames = sorted(all_frames)\n",
    "new_df_time_pep = pd.DataFrame(columns=all_frames, index=[1, 2, 3, 4])\n",
    "for index, row in structure_dataframe.iterrows():\n",
    "    for f in all_frames:\n",
    "        if f in row[\"cluster_frames\"]:\n",
    "            new_df_time_pep.loc[row[\"peptide\"], f] =  row[\"cluster\"]\n",
    "new_df_time_pep = new_df_time_pep[sorted(new_df_time_pep.columns.tolist())]\n",
    "new_df_time_pep.to_csv(f\"{working_output_dir}/clusters_time_frames_different_ref2.csv\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_umap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
